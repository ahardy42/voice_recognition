# Voice Recognition App

A modern, interactive voice recognition web application that provides real-time speech-to-text conversion with visual feedback. The app features dynamic background color changes based on voice intensity and animated waveform visualization.

## üöÄ Features

- **Real-time Speech Recognition**: Continuous speech-to-text conversion
- **Visual Feedback**: Dynamic background colors that change based on voice intensity
- **Animated Waveform**: Real-time audio visualization with animated bars
- **Responsive Design**: Works on desktop and mobile devices
- **Permission Management**: Graceful handling of microphone permissions
- **TypeScript**: Fully typed codebase for better development experience

## üõ†Ô∏è Technology Stack

### Core Technologies
- **TypeScript** - Type-safe JavaScript development
- **Vite** - Fast build tool and development server
- **Web Speech API** - Browser-native speech recognition
- **Web Audio API** - Real-time audio analysis and visualization

### Dependencies
- `typescript` (~5.8.3) - TypeScript compiler
- `vite` (^6.3.5) - Build tool and dev server
- `@types/dom-speech-recognition` (^0.0.6) - TypeScript definitions for Web Speech API

## üì¶ Installation & Setup

### Prerequisites
- Node.js (version 16 or higher)
- npm or yarn package manager
- A modern web browser with microphone support

### Installation Steps

1. **Clone the repository**
   ```bash
   git clone <repository-url>
   cd voice_recognition
   ```

2. **Install dependencies**
   ```bash
   npm install
   ```

3. **Start development server**
   ```bash
   npm run dev
   ```

4. **Open in browser**
   - Navigate to `http://localhost:5173` (or the URL shown in your terminal)
   - Allow microphone permissions when prompted

### Building for Production

1. **Build the application**
   ```bash
   npm run build
   ```

2. **Preview the production build**
   ```bash
   npm run preview
   ```

The built files will be in the `dist/` directory, ready for deployment to any static hosting service.

## üîß How It Works

### Architecture Overview

The application uses a combination of modern web APIs to provide real-time voice recognition with visual feedback:

1. **Web Speech API** - Handles speech recognition
2. **Web Audio API** - Analyzes audio for visual feedback
3. **Canvas API** - Provides smooth animations
4. **Permission API** - Manages microphone permissions

### Core Components

#### 1. Speech Recognition Engine
```typescript
const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
const recognition = new SpeechRecognition();
```
- Uses the browser's native speech recognition capabilities
- Configured for continuous recognition with interim results
- Supports multiple languages (default: English US)

**API Documentation**: [Web Speech API](https://developer.mozilla.org/en-US/docs/Web/API/Web_Speech_API)

#### 2. Audio Analysis System
```typescript
const audioContext = new AudioContext();
const analyser = audioContext.createAnalyser();
const microphone = audioContext.createMediaStreamSource(stream);
```
- Captures real-time audio from the microphone
- Analyzes frequency data for visual feedback
- Uses FFT (Fast Fourier Transform) for audio processing

**API Documentation**: [Web Audio API](https://developer.mozilla.org/en-US/docs/Web/API/Web_Audio_API)

#### 3. Visual Feedback Engine
- **Background Color Changes**: Dynamically adjusts based on voice intensity levels
- **Waveform Animation**: Real-time visualization of audio frequency data
- **Smooth Transitions**: CSS transitions for seamless visual changes

### Voice Intensity Levels

The app categorizes voice input into four intensity levels:

- **Voice Low** (0-30 amplitude): Cool blue tones
- **Voice Medium** (30-80 amplitude): Neutral background
- **Voice High** (80-150 amplitude): Warm orange tones
- **Voice Intense** (150+ amplitude): Hot red tones

### Permission Management

The app implements a robust permission handling system:

1. **Permission Check**: Verifies microphone access before starting
2. **Graceful Fallbacks**: Handles denied permissions with helpful error messages
3. **Browser-Specific Instructions**: Provides guidance for different browsers
4. **Modal Dialogs**: User-friendly permission request interfaces

## üåê Browser Compatibility

### Supported Browsers
- **Chrome/Edge** (Chromium-based) - Full support
- **Firefox** - Full support
- **Safari** - Limited support (may require HTTPS)

### Requirements
- HTTPS connection (required for microphone access in production)
- Microphone hardware
- Modern browser with Web Speech API support

## üîí Security Considerations

- **HTTPS Required**: Microphone access requires secure connection in production
- **Permission-Based**: Only accesses microphone after explicit user consent
- **No Data Storage**: Speech data is not stored or transmitted
- **Local Processing**: All audio analysis happens in the browser

## üöÄ Deployment

### Static Hosting
The built application can be deployed to any static hosting service:

- **Netlify**: Drag and drop the `dist/` folder
- **Vercel**: Connect your repository for automatic deployments
- **GitHub Pages**: Deploy from the `dist/` branch
- **AWS S3**: Upload files to an S3 bucket with static website hosting

### Environment Requirements
- HTTPS enabled (required for microphone access)
- Modern web server with proper MIME types
- CORS headers if needed for cross-origin requests

## üêõ Troubleshooting

### Common Issues

1. **Microphone not working**
   - Check browser permissions
   - Ensure HTTPS connection (required for production)
   - Try refreshing the page

2. **Speech recognition not starting**
   - Verify microphone is connected and working
   - Check browser console for errors
   - Ensure browser supports Web Speech API

3. **Visual feedback not working**
   - Check if audio analysis is properly initialized
   - Verify microphone permissions are granted
   - Check browser console for Web Audio API errors

### Browser-Specific Notes

- **Chrome**: Best support, recommended for development
- **Firefox**: Good support, may have slight differences in audio analysis
- **Safari**: Limited Web Speech API support, may not work as expected
- **Mobile Browsers**: Support varies, test thoroughly on target devices

## üìö Additional Resources

- [Web Speech API Documentation](https://developer.mozilla.org/en-US/docs/Web/API/Web_Speech_API)
- [Web Audio API Documentation](https://developer.mozilla.org/en-US/docs/Web/API/Web_Audio_API)
- [MediaDevices API](https://developer.mozilla.org/en-US/docs/Web/API/MediaDevices)
- [Vite Documentation](https://vitejs.dev/)
- [TypeScript Documentation](https://www.typescriptlang.org/)

## ü§ù Contributing

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

## üìÑ License

This project is licensed under the MIT License - see the LICENSE file for details.

---

**Note**: This application requires microphone access and works best in modern browsers with Web Speech API support. For production use, ensure your hosting environment supports HTTPS. 